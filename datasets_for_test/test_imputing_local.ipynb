{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36529917-49cd-4b30-8ed4-df9dd546c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04377cd7-e87c-4cc0-b330-38dec37840c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e11fa3-15a5-494b-8b68-e7efa5be7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 2000, num = 15)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7654214-dd8d-463b-859c-0ae728cfc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid =  { \n",
    "                'randomforest__n_estimators': n_estimators,\n",
    "               #'max_features': max_features,\n",
    "               'randomforest__max_depth': max_depth,\n",
    "               'randomforest__min_samples_split': min_samples_split,\n",
    "               'randomforest__min_samples_leaf': min_samples_leaf,\n",
    "               'randomforest__bootstrap': bootstrap\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ded95c7-3ec1-441d-898d-e4a0f0982436",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data_train = pd.read_csv(\"train_data.csv\",index_col=0)\n",
    "original_labels_train = pd.read_csv(\"train_labels.csv\",index_col=0)\n",
    "original_data_test = pd.read_csv(\"test_data.csv\",index_col=0)\n",
    "original_labels_test = pd.read_csv(\"test_labels.csv\",index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a62542e7-ff09-4ef8-9a63-79cb87f29454",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels_train = original_labels_train.sort_index()\n",
    "original_labels_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "original_data_train = original_data_train.copy().sort_index()\n",
    "original_data_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8a7f7-ed5c-457c-9603-03e6f6a9f446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba7800-a132-4d88-9b43-d66f8532a58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f4684d6-fa8e-42a2-af07-4e1f2975bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_data_train = pd.read_csv(\"train_data_corrupted.csv\",index_col=0)\n",
    "corrupted_data_test = pd.read_csv(\"test_data_corrupted.csv\",index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "38168eee-23c9-4cd5-a00d-68344c0e0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_data_train = corrupted_data_train.sort_index()\n",
    "corrupted_data_train.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c52050ff-20c0-4d18-942c-8c7729f6ce11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_labels_train.index.equals(corrupted_data_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5063a3c-8a90-4ee0-a480-fa11024a7bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b56955-8fcc-4317-9d32-d867dfb28f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>35.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.43</td>\n",
       "      <td>33.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>29.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.97</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>31.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>61.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.20</td>\n",
       "      <td>33.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8174 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1    V2    V3    V4    V5     V6     V7\n",
       "2107  3.0   1.0  27.0  23.0  27.0  22.00  35.47\n",
       "1400  4.0   7.0  25.0  15.0  30.0   9.43  33.54\n",
       "9117  0.0   0.0   0.0   0.0  20.0  20.00  29.41\n",
       "5369  5.0   0.0   6.0  18.0   0.0  18.97    NaN\n",
       "9215  0.0   0.0   0.0   0.0  22.0  22.00  31.62\n",
       "...   ...   ...   ...   ...   ...    ...    ...\n",
       "5734  0.0  28.0   0.0   0.0  10.0  29.73    NaN\n",
       "5191  4.0  19.0  21.0   0.0   6.0  24.21    NaN\n",
       "5390  0.0   0.0   0.0   0.0  36.0  36.00  61.85\n",
       "860   1.0  22.0   0.0  22.0   7.0   7.00    NaN\n",
       "7270  3.0   1.0  29.0  11.0  31.0  10.20  33.24\n",
       "\n",
       "[8174 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c30f28-dd69-432b-b033-fac5b3e91bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_transform_train(train_data, train_labels, categorical_columns, numerical_columns):\n",
    "        # Define the categorical preprocessing pipeline\n",
    "        categorical_preprocessing = Pipeline(\n",
    "            [\n",
    "                ('mark_missing', SimpleImputer(strategy='most_frequent')),\n",
    "                ('one_hot_encode', OneHotEncoder(handle_unknown='ignore',sparse= False))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Define the numerical preprocessing pipeline\n",
    "        numerical_preprocessing = Pipeline(\n",
    "            [\n",
    "                ('mark_missing', SimpleImputer(strategy='mean')),\n",
    "                ('scaling', StandardScaler())\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Define the column transformer\n",
    "        feature_transformation = ColumnTransformer(transformers=[\n",
    "                ('categorical_features', categorical_preprocessing, categorical_columns),\n",
    "                ('scaled_numeric', numerical_preprocessing, numerical_columns)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Sort and reset indices for train_labels and train_data\n",
    "        labels = train_labels.sort_index()\n",
    "        labels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        train_data_sorted = train_data.copy().sort_index()\n",
    "        train_data_sorted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Transform the data\n",
    "        \n",
    "        if not categorical_columns and not numerical_columns:\n",
    "            raise ValueError(\"categorical_columns list and numerical_columns list are empty. Feature Prep. Pipeline needs imput!\")\n",
    "        else:\n",
    "            transformed_data = pd.DataFrame(feature_transformation.fit_transform(train_data_sorted))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Add the labels to the transformed data\n",
    "\n",
    "        transformed_data[\"train_label\"] = labels\n",
    "        #transformed_data.to_csv(\"debug.csv\")\n",
    "        return transformed_data, feature_transformation, labels\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dce7d777-6d60-4724-b67f-8fe46654cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    " transformed_data, feature_transformation, labels = preprocess_and_transform_train(corrupted_data_train.copy(),original_labels_train.copy(),[],[\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fc799f9-8014-42b7-8730-152cfe5d30d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       7.234685e-16\n",
       "1       7.234685e-16\n",
       "2       7.234685e-16\n",
       "3       7.234685e-16\n",
       "4       7.234685e-16\n",
       "            ...     \n",
       "8169    7.234685e-16\n",
       "8170    7.234685e-16\n",
       "8171    7.234685e-16\n",
       "8172    7.234685e-16\n",
       "8173    7.234685e-16\n",
       "Name: 6, Length: 8174, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52910d66-3134-498e-92be-4b014ca10e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240904_084731\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240904_084731\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.8.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       21.79 GB / 31.95 GB (68.2%)\n",
      "Disk Space Avail:   403.55 GB / 931.51 GB (43.3%)\n",
      "===================================================\n",
      "Train Data Rows:    8174\n",
      "Train Data Columns: 7\n",
      "Label Column:       train_label\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t10 unique label values:  [1, 4, 5, 6, 7, 8, 9, 10, 2, 3]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting IdentityFeatureGenerator...\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7356, Val Rows: 818\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'XGB': {},\n",
      "}\n",
      "Excluded models: [] (Specified by `excluded_model_types`)\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost ... Training model for up to 59.97s of the 59.97s of remaining time.\n",
      "\t0.846\t = Validation score   (accuracy)\n",
      "\t13.5s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.97s of the 46.05s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost': 1.0}\n",
      "\t0.846\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.0s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240904_084731\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "                 model  score_val eval_metric  pred_time_val   fit_time  \\\n",
      "0              XGBoost   0.845966    accuracy       0.139001  13.496633   \n",
      "1  WeightedEnsemble_L2   0.845966    accuracy       0.140001  13.504630   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                0.139001          13.496633            1       True   \n",
      "1                0.001001           0.007997            2       True   \n",
      "\n",
      "   fit_order  \n",
      "0          1  \n",
      "1          2  \n"
     ]
    }
   ],
   "source": [
    "excluded_model_types = ['KNN','CAT','FASTAI','XT','GBM',\"RF\",\"NN_TORCH\"]\n",
    "\n",
    "model = TabularPredictor(label=\"train_label\").fit(transformed_data,time_limit=60,excluded_model_types=excluded_model_types,hyperparameters={ 'XGB':{}},feature_generator=None)\n",
    "print(\"---------------------------\")\n",
    "print(model.leaderboard())\n",
    "model.delete_models(models_to_keep='best', dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab199b-0ceb-427d-a981-5b16d9008c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59dd10e6-7c6e-4b3f-95f9-8737faeef6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_transform_test(tets_data, test_labels, feature_transformer):\n",
    "            # Define the categorical preprocessing pipeline\n",
    "            \n",
    "            \n",
    "            # Sort and reset indices for test_labels and tets_data\n",
    "            labels = test_labels.sort_index()\n",
    "            labels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            tets_data_sorted = tets_data.copy().sort_index()\n",
    "            tets_data_sorted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # Transform the data\n",
    "\n",
    "            categorical_columns = []\n",
    "            numerical_columns =[\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\"]\n",
    "            if not categorical_columns and not numerical_columns:\n",
    "                 raise ValueError(\"categorical_columns list and numerical_columns list are empty. Feature Prep. Pipeline needs imput!\")\n",
    "            else:\n",
    "                transformed_data = pd.DataFrame(feature_transformer.transform(tets_data_sorted))\n",
    "\n",
    "            \n",
    "            \n",
    "            # Add the labels to the transformed data\n",
    "\n",
    "\n",
    "            return transformed_data, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bccc5ca-5983-4619-b683-66799766910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_test, test_labels_sorted = preprocess_and_transform_test(original_data_test.copy(),original_labels_test.copy(), feature_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c96849dc-3cfa-4c4d-bbdf-346368c1a70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.517600    24\n",
       " 0.393681    21\n",
       "-0.603129    20\n",
       "-0.061451    16\n",
       " 0.001677    16\n",
       "             ..\n",
       "-1.380009     1\n",
       " 2.091006     1\n",
       "-0.751784     1\n",
       " 0.149315     1\n",
       "-0.346544     1\n",
       "Name: 6, Length: 482, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_test[6].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6ad43-59cc-4682-bf0c-ae4887bb83e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2262ca78-2bde-4126-8c58-5af75e217216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corrupted_predictions  = model.predict(corrupted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "613d47fa-60a0-45be-aa3e-cbaaf347c1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7567210005150592"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_labels_sorted, corrupted_predictions, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1dc7a3-5d32-42e2-ada0-333c0967dbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "638bb03d-78f6-4ebf-b2a5-fe81a5d0b531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>35.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.43</td>\n",
       "      <td>33.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>29.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.97</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>31.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>61.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.20</td>\n",
       "      <td>33.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8174 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1    V2    V3    V4    V5     V6     V7\n",
       "2107  3.0   1.0  27.0  23.0  27.0  22.00  35.47\n",
       "1400  4.0   7.0  25.0  15.0  30.0   9.43  33.54\n",
       "9117  0.0   0.0   0.0   0.0  20.0  20.00  29.41\n",
       "5369  5.0   0.0   6.0  18.0   0.0  18.97    NaN\n",
       "9215  0.0   0.0   0.0   0.0  22.0  22.00  31.62\n",
       "...   ...   ...   ...   ...   ...    ...    ...\n",
       "5734  0.0  28.0   0.0   0.0  10.0  29.73    NaN\n",
       "5191  4.0  19.0  21.0   0.0   6.0  24.21    NaN\n",
       "5390  0.0   0.0   0.0   0.0  36.0  36.00  61.85\n",
       "860   1.0  22.0   0.0  22.0   7.0   7.00    NaN\n",
       "7270  3.0   1.0  29.0  11.0  31.0  10.20  33.24\n",
       "\n",
       "[8174 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78627744-d080-4747-a963-356f8e0d9bf2",
   "metadata": {},
   "source": [
    "## Imputation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4825ae06-8e9b-4130-8da1-2f350a7f4773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "58a63729-f646-494c-ba7a-a53986159a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_data_train = pd.read_csv(\"train_data_corrupted.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "88d515c5-33cc-478e-8d83-05541a8ff7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_mask = corrupted_data_train[\"V7\"].isna()\n",
    "df_train= corrupted_data_train[~missing_mask]\n",
    "df_with_missing = corrupted_data_train[missing_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8618c298-0bc0-476e-acc5-a7e604a7ff12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.97</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>26.08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6946</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4087 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1    V2    V3    V4    V5     V6  V7\n",
       "5369  5.0   0.0   6.0  18.0   0.0  18.97 NaN\n",
       "6041  0.0  18.0   0.0   2.0   9.0  18.36 NaN\n",
       "4453  0.0   0.0   0.0   0.0  20.0  20.00 NaN\n",
       "3745  2.0   0.0  18.0  26.0  16.0  26.08 NaN\n",
       "6946  1.0   0.0  17.0   1.0  33.0  16.03 NaN\n",
       "...   ...   ...   ...   ...   ...    ...  ..\n",
       "4426  4.0  13.0  33.0  13.0  27.0   6.00 NaN\n",
       "466   4.0  17.0  12.0  17.0  18.0   6.00 NaN\n",
       "5734  0.0  28.0   0.0   0.0  10.0  29.73 NaN\n",
       "5191  4.0  19.0  21.0   0.0   6.0  24.21 NaN\n",
       "860   1.0  22.0   0.0  22.0   7.0   7.00 NaN\n",
       "\n",
       "[4087 rows x 7 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b662d8e1-dac7-4ac7-b480-7d292bd39614",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= \n",
    "X= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "eb8b6ac8-931a-4509-91c0-9cf6158948ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4087 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1    V2    V3    V4    V5     V6\n",
       "2107  3.0   1.0  27.0  23.0  27.0  22.00\n",
       "1400  4.0   7.0  25.0  15.0  30.0   9.43\n",
       "9117  0.0   0.0   0.0   0.0  20.0  20.00\n",
       "9215  0.0   0.0   0.0   0.0  22.0  22.00\n",
       "6492  1.0   0.0  23.0   6.0  20.0   6.71\n",
       "...   ...   ...   ...   ...   ...    ...\n",
       "1685  1.0   0.0  24.0  10.0  18.0  11.66\n",
       "8322  3.0   0.0  19.0   1.0  31.0  12.04\n",
       "6265  4.0  12.0   8.0   6.0   4.0   7.21\n",
       "5390  0.0   0.0   0.0   0.0  36.0  36.00\n",
       "7270  3.0   1.0  29.0  11.0  31.0  10.20\n",
       "\n",
       "[4087 rows x 6 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e460e768-300e-495a-8671-29850f85f627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " df_train_imp, feature_transformation, labels = preprocess_and_transform_train(df_train.iloc[:,:-1],df_train.iloc[:,-1:],[],[\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e945fb22-d841-41a6-b677-8c513c05acef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240830_154130\"\n",
      "Presets specified: ['high_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 360 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels\\ag-20240830_154130/ds_sub_fit/sub_fit_ho.\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n",
      "Spend 25 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 335 seconds.\n",
      "Starting full fit now with num_stack_levels 0.\n",
      "Beginning AutoGluon training ... Time limit = 335s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240830_154130\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.8.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       16.78 GB / 31.95 GB (52.5%)\n",
      "Disk Space Avail:   343.51 GB / 931.51 GB (36.9%)\n",
      "===================================================\n",
      "Train Data Rows:    4087\n",
      "Train Data Columns: 6\n",
      "Label Column:       train_label\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting IdentityFeatureGenerator...\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'XGB': {},\n",
      "}\n",
      "Excluded models: [] (Specified by `excluded_model_types`)\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 334.97s of the 334.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-4.1673\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.06s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 334.97s of the 322.48s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
      "\t-4.1673\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.56s ... Best model: \"WeightedEnsemble_L2\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t1.39s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
      "\t0.0s\t = Training   runtime\n",
      "Updated best model to \"XGBoost_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"XGBoost_BAG_L1_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 1.47s ... Best model: \"XGBoost_BAG_L1_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240830_154130\")\n",
      "Deleting model XGBoost_BAG_L1. All files under AutogluonModels\\ag-20240830_154130\\models\\XGBoost_BAG_L1 will be removed.\n",
      "Deleting model WeightedEnsemble_L2. All files under AutogluonModels\\ag-20240830_154130\\models\\WeightedEnsemble_L2 will be removed.\n",
      "Deleting model WeightedEnsemble_L2_FULL. All files under AutogluonModels\\ag-20240830_154130\\models\\WeightedEnsemble_L2_FULL will be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "                      model  score_val              eval_metric  \\\n",
      "0            XGBoost_BAG_L1  -4.167295  root_mean_squared_error   \n",
      "1       WeightedEnsemble_L2  -4.167295  root_mean_squared_error   \n",
      "2       XGBoost_BAG_L1_FULL        NaN  root_mean_squared_error   \n",
      "3  WeightedEnsemble_L2_FULL        NaN  root_mean_squared_error   \n",
      "\n",
      "   pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
      "0       0.502948  5.063996                0.502948           5.063996   \n",
      "1       0.503948  5.066996                0.001000           0.003000   \n",
      "2            NaN  1.388998                     NaN           1.388998   \n",
      "3            NaN  1.391999                     NaN           0.003000   \n",
      "\n",
      "   stack_level  can_infer  fit_order  \n",
      "0            1      False          1  \n",
      "1            2      False          2  \n",
      "2            1       True          3  \n",
      "3            2       True          4  \n"
     ]
    }
   ],
   "source": [
    "excluded_model_types = ['KNN','CAT','FASTAI','XT','GBM',\"RF\",\"NN_TORCH\"]\n",
    "\n",
    "\n",
    "imputer = TabularPredictor(label=\"train_label\").fit(df_train_imp,time_limit=360,presets=\"high_quality\",excluded_model_types=excluded_model_types,hyperparameters={ 'XGB':{}},feature_generator=None)\n",
    "print(\"---------------------------\")\n",
    "print(imputer.leaderboard())\n",
    "imputer.delete_models(models_to_keep='best', dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b4223e9-1bf6-4223-9bb5-837b589f4e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Petro\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                                             (&#x27;randomforest&#x27;,\n",
       "                                              RandomForestRegressor())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;randomforest__bootstrap&#x27;: [True,\n",
       "                                                                    False],\n",
       "                                        &#x27;randomforest__max_depth&#x27;: [10, 20, 30,\n",
       "                                                                    40, 50, 60,\n",
       "                                                                    70, 80, 90,\n",
       "                                                                    100, 110,\n",
       "                                                                    None],\n",
       "                                        &#x27;randomforest__min_samples_leaf&#x27;: [1, 2,\n",
       "                                                                           4],\n",
       "                                        &#x27;randomforest__min_samples_split&#x27;: [2,\n",
       "                                                                            5,\n",
       "                                                                            10],\n",
       "                                        &#x27;randomforest__n_estimators&#x27;: [10, 152,\n",
       "                                                                       294, 436,\n",
       "                                                                       578, 720,\n",
       "                                                                       862,\n",
       "                                                                       1005,\n",
       "                                                                       1147,\n",
       "                                                                       1289,\n",
       "                                                                       1431,\n",
       "                                                                       1573,\n",
       "                                                                       1715,\n",
       "                                                                       1857,\n",
       "                                                                       2000]},\n",
       "                   random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                                             (&#x27;randomforest&#x27;,\n",
       "                                              RandomForestRegressor())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;randomforest__bootstrap&#x27;: [True,\n",
       "                                                                    False],\n",
       "                                        &#x27;randomforest__max_depth&#x27;: [10, 20, 30,\n",
       "                                                                    40, 50, 60,\n",
       "                                                                    70, 80, 90,\n",
       "                                                                    100, 110,\n",
       "                                                                    None],\n",
       "                                        &#x27;randomforest__min_samples_leaf&#x27;: [1, 2,\n",
       "                                                                           4],\n",
       "                                        &#x27;randomforest__min_samples_split&#x27;: [2,\n",
       "                                                                            5,\n",
       "                                                                            10],\n",
       "                                        &#x27;randomforest__n_estimators&#x27;: [10, 152,\n",
       "                                                                       294, 436,\n",
       "                                                                       578, 720,\n",
       "                                                                       862,\n",
       "                                                                       1005,\n",
       "                                                                       1147,\n",
       "                                                                       1289,\n",
       "                                                                       1431,\n",
       "                                                                       1573,\n",
       "                                                                       1715,\n",
       "                                                                       1857,\n",
       "                                                                       2000]},\n",
       "                   random_state=42, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;randomforest&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('scale', StandardScaler()),\n",
       "                                             ('randomforest',\n",
       "                                              RandomForestRegressor())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'randomforest__bootstrap': [True,\n",
       "                                                                    False],\n",
       "                                        'randomforest__max_depth': [10, 20, 30,\n",
       "                                                                    40, 50, 60,\n",
       "                                                                    70, 80, 90,\n",
       "                                                                    100, 110,\n",
       "                                                                    None],\n",
       "                                        'randomforest__min_samples_leaf': [1, 2,\n",
       "                                                                           4],\n",
       "                                        'randomforest__min_samples_split': [2,\n",
       "                                                                            5,\n",
       "                                                                            10],\n",
       "                                        'randomforest__n_estimators': [10, 152,\n",
       "                                                                       294, 436,\n",
       "                                                                       578, 720,\n",
       "                                                                       862,\n",
       "                                                                       1005,\n",
       "                                                                       1147,\n",
       "                                                                       1289,\n",
       "                                                                       1431,\n",
       "                                                                       1573,\n",
       "                                                                       1715,\n",
       "                                                                       1857,\n",
       "                                                                       2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "pip = Pipeline(steps=[\n",
    "\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"randomforest\", rf)\n",
    "])\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = pip, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53231421-c1ee-49a4-954a-240ea5a2ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest= rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c40fe18a-02bd-4b5f-941b-acd0d528bc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       32.231998\n",
       "1       27.535999\n",
       "2       34.824001\n",
       "3       29.518000\n",
       "4       20.548000\n",
       "          ...    \n",
       "8169    56.127998\n",
       "8170    58.172001\n",
       "8171    58.632000\n",
       "8172    39.292000\n",
       "8173    58.790001\n",
       "Name: V7, Length: 4087, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_data_train.loc[missing_mask].iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b1dc288d-9cb3-4df3-894e-d7392e089569",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_mask = corrupted_data_train[\"V7\"].isna()\n",
    "amount_missing_in_columns = missing_mask.sum()\n",
    "column= \"V7\"\n",
    "corrupted_data_train.loc[missing_mask, column] = imputer.predict(corrupted_data_train.loc[missing_mask].iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "df7bdec5-497d-45da-8dc9-ead6091a6944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = imputer.predict(df_with_missing.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2c86075b-2f5c-4f90-91c2-9ab41fc42b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_with_missing[\"V7\"] = prediction\n",
    "#df_new_imputed = df_train._append(df_with_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b6a61f62-6703-4642-ae5b-16031d8a2e7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>35.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.43</td>\n",
       "      <td>33.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>29.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.97</td>\n",
       "      <td>46.152866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>31.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.73</td>\n",
       "      <td>63.167416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.21</td>\n",
       "      <td>47.628090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>61.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>36.602909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.20</td>\n",
       "      <td>33.240000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8174 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1    V2    V3    V4    V5     V6         V7\n",
       "2107  3.0   1.0  27.0  23.0  27.0  22.00  35.470000\n",
       "1400  4.0   7.0  25.0  15.0  30.0   9.43  33.540000\n",
       "9117  0.0   0.0   0.0   0.0  20.0  20.00  29.410000\n",
       "5369  5.0   0.0   6.0  18.0   0.0  18.97  46.152866\n",
       "9215  0.0   0.0   0.0   0.0  22.0  22.00  31.620000\n",
       "...   ...   ...   ...   ...   ...    ...        ...\n",
       "5734  0.0  28.0   0.0   0.0  10.0  29.73  63.167416\n",
       "5191  4.0  19.0  21.0   0.0   6.0  24.21  47.628090\n",
       "5390  0.0   0.0   0.0   0.0  36.0  36.00  61.850000\n",
       "860   1.0  22.0   0.0  22.0   7.0   7.00  36.602909\n",
       "7270  3.0   1.0  29.0  11.0  31.0  10.20  33.240000\n",
       "\n",
       "[8174 rows x 7 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041a3af-4f2c-4dfa-8ef0-19d4073af4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7391d8f-f599-444f-b4a2-6bb12a9fde37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "77fd5e24-3fda-40fc-9554-70c0448a06ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data, feature_transformation, labels = preprocess_and_transform_train(corrupted_data_train.copy(),original_labels_train.copy(),[],[\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d152bc-8255-4490-983d-1ae1a0acf7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4cedc1d1-76c3-4738-9906-2cdb42fa2d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240830_154213\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240830_154213\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.8.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       16.98 GB / 31.95 GB (53.1%)\n",
      "Disk Space Avail:   343.50 GB / 931.51 GB (36.9%)\n",
      "===================================================\n",
      "Train Data Rows:    8174\n",
      "Train Data Columns: 7\n",
      "Label Column:       train_label\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t10 unique label values:  [1, 4, 5, 6, 7, 8, 9, 10, 2, 3]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting IdentityFeatureGenerator...\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7356, Val Rows: 818\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'XGB': {},\n",
      "}\n",
      "Excluded models: [] (Specified by `excluded_model_types`)\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost ... Training model for up to 59.97s of the 59.97s of remaining time.\n",
      "\t0.8301\t = Validation score   (accuracy)\n",
      "\t9.24s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.97s of the 50.31s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost': 1.0}\n",
      "\t0.8301\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.73s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240830_154213\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "                 model  score_val eval_metric  pred_time_val  fit_time  \\\n",
      "0              XGBoost   0.830073    accuracy       0.138000  9.242995   \n",
      "1  WeightedEnsemble_L2   0.830073    accuracy       0.138999  9.247997   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                0.138000           9.242995            1       True   \n",
      "1                0.000999           0.005002            2       True   \n",
      "\n",
      "   fit_order  \n",
      "0          1  \n",
      "1          2  \n"
     ]
    }
   ],
   "source": [
    "excluded_model_types = ['KNN','CAT','FASTAI','XT','GBM',\"RF\",\"NN_TORCH\"]\n",
    "\n",
    "\n",
    "models = TabularPredictor(label=\"train_label\").fit(transformed_data,time_limit=60,excluded_model_types=excluded_model_types,hyperparameters={ 'XGB':{}},feature_generator=None)\n",
    "print(\"---------------------------\")\n",
    "print(models.leaderboard())\n",
    "models.delete_models(models_to_keep='best', dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ccf275-5d33-4725-9d83-f0d4cf5d530e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ffb2a246-2678-40b4-ac58-aa50d1fa668e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imputed_predictions  = models.predict(corrupted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "21bb2f49-ea63-4e7d-90c0-9db9cc0bd1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6960925545931959"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_labels_sorted, imputed_predictions, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa57385b-ee57-4bee-a1df-d776c8fa143e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0245d832-35e3-44a0-bb04-2ac4ecb5ced3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed8978d2-3837-4b50-8dc6-c28c3705661b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19ad690b-ce16-41cd-97ce-d0d53bfe1ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960fe50d-c7f8-4cd8-b280-d1be011df6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb92312c-6471-4334-9c05-597e87ae6162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04afd8f-d39b-47ef-84bd-8567f0ac6662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69f1e5-a666-4507-b705-1ba023c2dcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ce0343a1-d63e-4c55-b8a5-1d758078a56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240828_153907\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.8.19\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jun 18 14:36:16 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       52.54 GB / 62.01 GB (84.7%)\n",
      "Disk Space Avail:   1648.32 GB / 1832.21 GB (90.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240828_153907\"\n",
      "Train Data Rows:    8174\n",
      "Train Data Columns: 7\n",
      "Label Column:       V7\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (76.22, 13.89, 40.47956, 10.37799)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting IdentityFeatureGenerator...\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Data preprocessing and feature engineering runtime = 0.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 7356, Val Rows: 818\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'XGB': {},\n",
      "}\n",
      "Excluded models: [] (Specified by `excluded_model_types`)\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost ... Training model for up to 359.99s of the 359.99s of remaining time.\n",
      "/home/ptsialis/.conda/envs/Data-Imputation-Thesis/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [17:39:07] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ptsialis/.conda/envs/Data-Imputation-Thesis/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [17:39:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ptsialis/.conda/envs/Data-Imputation-Thesis/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [17:39:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ptsialis/.conda/envs/Data-Imputation-Thesis/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [17:39:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\t-3.5046\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.99s of the 359.04s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost': 1.0}\n",
      "\t-3.5046\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.98s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 167575.5 rows/s (818 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240828_153907\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0              XGBoost  -3.504626  root_mean_squared_error       0.004656   \n",
      "1  WeightedEnsemble_L2  -3.504626  root_mean_squared_error       0.004881   \n",
      "\n",
      "   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  0.943475                0.004656           0.943475            1   \n",
      "1  0.944741                0.000226           0.001266            2   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          1  \n",
      "1       True          2  \n"
     ]
    }
   ],
   "source": [
    "excluded_model_types = ['KNN', 'CAT','FASTAI','XT','GBM','RF','NN_TORCH']\n",
    "\n",
    "\n",
    "model = TabularPredictor(label=\"V7\").fit(df_new,time_limit=360,excluded_model_types=excluded_model_types,hyperparameters={'XGB':{}},feature_generator=None,ag_args_fit={'num_gpus': 1},ag_args_ensemble =dict(fold_fitting_strategy='sequential_local'))\n",
    "print(\"---------------------------\")\n",
    "print(model.leaderboard())\n",
    "\n",
    "\n",
    "model.delete_models(models_to_keep='best', dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0d41d-ff85-4651-951c-c0210d110cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788ffe7-8025-4e2a-9569-cb7b6e2bce5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14923af4-7cfb-46e5-988f-0594050f7be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bcbf9-f130-4f82-8118-79598960a5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
